{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mjawad4/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/mjawad4/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mjawad4/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'PRP'), ('and', 'CC'), ('I', 'PRP'), ('are', 'VBP'), ('best', 'JJS'), ('friends', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text\n",
    "text = \"He and I are best friends\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Get POS tags for the tokens\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "tag_list = [tag for _, tag in pos_tags]\n",
    "\n",
    "# Print the POS tags\n",
    "print(pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP', 'CC', 'NNP', 'VBZ', 'CD', 'NNS', 'JJ', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word order -> Can be determined using a dictionary set of rules?\n",
    "# Subject-verb agreement -> Can be determined by creating rules by creating a dictionary, where keys are nouns, values are allowed verbs\n",
    "\n",
    "tag_rule_set = {}\n",
    "tag_rule_set['NNP'] = ['CC', 'POS', 'RB', 'WDT', 'WP$', 'VBD', 'VBG', 'VBZ', 'WP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_after_token_preprocessing(tokens):\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tags = [tag for _, tag in tags]\n",
    "    for i in range (1,len(tags)-1):\n",
    "        if tags[i]=='CC' and tokens[i]=='and':\n",
    "            if tags[i-1] in ['NNP', 'NN', 'PRP'] and tags[i+1]in ['NNP', 'NN', 'PRP']:\n",
    "                tags[i]='NNPS'\n",
    "                tags[i-1]=''\n",
    "                tags[i+1]=''\n",
    "    return [x for x in tags if x != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['James', 'is', 'a', 'boy']\n",
      "Tags: ['NNP', 'VBZ', 'DT', 'NN']\n",
      "Transformed tags: ['NNP', 'VBZ', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "sent = 'James is a boy'\n",
    "print(word_tokenize(sent))\n",
    "tags_after_processing = tags_after_token_preprocessing(word_tokenize(sent))\n",
    "print(f'Transformed tags: {tags_after_processing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_verb_agreement_noun(subject_tag, verb_tag):\n",
    "    # define rules for subject-verb agreement\n",
    "    tag_rule_set = {}\n",
    "    tag_rule_set['NN'] = ['VBD', 'VBG', 'VBZ']\n",
    "    tag_rule_set['NNS'] = ['VB', 'VBD', 'VBG', 'VBP']\n",
    "    tag_rule_set['NNP'] = ['VBD', 'VBG', 'VBZ']\n",
    "    tag_rule_set['NNPS'] = ['VB', 'VBD', 'VBG', 'VBP']\n",
    "\n",
    "    allowed_tags = tag_rule_set.get(subject_tag)\n",
    "    if verb_tag not in allowed_tags:\n",
    "        print('Subject verb disagreement')\n",
    "        print(f'Given tag: {verb_tag}')\n",
    "        print(f'Expected tag: {allowed_tags}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_verb_agreement_pronoun(corresponding_word, verb_tag):\n",
    "    # define rules for subject-verb agreement\n",
    "    corresponding_word = corresponding_word.lower()\n",
    "    allowed_tags = []\n",
    "    if corresponding_word in ['i', 'you', 'we', 'they']:\n",
    "        allowed_tags = ['VB', 'VBD', 'VBP']\n",
    "    elif corresponding_word in ['he', 'she', 'it']:\n",
    "        allowed_tags = ['VBD', 'VBZ']\n",
    "    elif corresponding_word in ['him', 'her', 'me', 'them', 'us', 'myself', 'yourself', 'himself', 'herself', 'itself', 'themselves', 'ourselves', 'yourselves']:\n",
    "    # else:\n",
    "        allowed_tags = ['VBG', 'VBN']\n",
    "    if verb_tag not in allowed_tags:\n",
    "        print('Subject verb disagreement')\n",
    "        print(f'Given tag: {verb_tag}')\n",
    "        print(f'Expected tag: {allowed_tags}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRP', 'MD', 'VB', '.']\n"
     ]
    }
   ],
   "source": [
    "test_sent = 'I will ate.'\n",
    "tokens = word_tokenize(test_sent)\n",
    "pos_tags = tags_after_token_preprocessing(tokens)\n",
    "print(pos_tags)\n",
    "for i in range(len(pos_tags)-1):\n",
    "    if pos_tags[i] in ['NN','NNS', 'NNP', 'NNPS'] and pos_tags[i+1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "        subject_tag = pos_tags[i]\n",
    "        verb_tag = pos_tags[i+1]\n",
    "        subject_verb_agreement_noun(subject_tag, verb_tag)\n",
    "    if pos_tags[i] in ['PRP'] and pos_tags[i+1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'] and (i+1)<len(pos_tags):\n",
    "        corresponding_word = tokens[i]\n",
    "        verb_tag = pos_tags[i+1]\n",
    "        subject_verb_agreement_pronoun(corresponding_word, verb_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
